{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImQMBaARXupK"
   },
   "source": [
    "## Narural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pnw6pnUXOLiQ"
   },
   "source": [
    "### Import Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwld9Ech8TxH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72XV5PRz0eFm"
   },
   "source": [
    "    Steps:\n",
    "    1. First we need to initialize the parameters based on the input, output and hidden layer dimension.\n",
    "    2. Then we calculate the cost or loss by forward propagation.\n",
    "    3. Then we calculate the gradients of the cost function w.r.t the parameters in backward propagation.\n",
    "    4. Then we update the parameters based on the gradients and learning rate. (Gradient Descent algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sj4Q1VR5uZ76"
   },
   "source": [
    "### Parameter Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRYA8-kt8Tx2"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(input_dim, hidden_dim, output_dim):\n",
    "\n",
    "  ## Two weight matrix and two bias vectors\n",
    "  W1 = np.random.randn(input_dim, hidden_dim)\n",
    "  b1 = np.zeros((1,hidden_dim))\n",
    "  W2 = np.random.randn(hidden_dim, output_dim)\n",
    "  b2 = np.zeros((1,output_dim))\n",
    "\n",
    "  ## Create a dictionary for the parameters\n",
    "  parameters = {\"W1\": W1, \"b1\" : b1, \"W2\": W2, \"b2\" : b2}\n",
    "\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMdyJY-oueLj"
   },
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmJyQBe98Tz4"
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "\n",
    "    ## We need the parameters to calculate the values\n",
    "    W1, b1, W2, b2  = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n",
    "\n",
    "    ## Forward Proapagation\n",
    "\n",
    "    Z1 = X.dot(W1) + b1\n",
    "\n",
    "    ## tanh activation for hidden layer\n",
    "    A1 = np.tanh(Z1)\n",
    "\n",
    "    Z2 = A1.dot(W2) + b2\n",
    "    \n",
    "    ## Softmax activation for output layer\n",
    "    exp_scores = np.exp(Z2)\n",
    "    A2 = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)            \n",
    " \n",
    "    fp_output = {\"A1\": A1,\"A2\": A2}\n",
    "    return fp_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUNdYcikum3E"
   },
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ok2uFfCZ8T0g"
   },
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, fp_output, parameters):\n",
    "\n",
    "    ## Closed form solution is used\n",
    "    ## Need A1 and A2 obtained in forward prop\n",
    "    A1 = fp_output[\"A1\"]\n",
    "    A2 = fp_output[\"A2\"]\n",
    "\n",
    "    W2 = parameters[\"W2\"]\n",
    "\n",
    "    ## Calculated Gradients\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (A1.T).dot(dZ2)\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "    dZ1 = dZ2.dot(W2.T) * (1 - np.power(A1, 2))\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0)\n",
    "\n",
    "    ## Dictionary to keep gradients for different parameters\n",
    "    gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "\n",
    "    return gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vixi9DmSuq2L"
   },
   "source": [
    "### Update Parameters (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9iyKGXP8T09"
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "\n",
    "  ## Learning rate is provided for GD\n",
    "  lr = learning_rate\n",
    "\n",
    "  ## Need parameters and gradient values\n",
    "  W1, b1, W2, b2  = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n",
    "  dW1, db1, dW2, db2  = gradients[\"dW1\"], gradients[\"db1\"], gradients[\"dW2\"], gradients[\"db2\"]\n",
    "\n",
    "  ## Update the parameters\n",
    "  W1 = W1 - lr*dW1\n",
    "  b1 = b1 - lr*db1\n",
    "  W2 = W2 - lr*dW2\n",
    "  b2 = b2 - lr*db2\n",
    "  \n",
    "  ## Create a dictionary for updated parameters\n",
    "  updated_parameters = {\"W1\": W1, \"W2\": W2, \"b1\" : b1, \"b2\" : b2}\n",
    "\n",
    "  return updated_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2m1uGxu13Bj"
   },
   "source": [
    "    Here we created a function to calculate cost.\n",
    "    Cost function is categorical cross-entropy.\n",
    "    It is calculated using the predicted values by the model and true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTlg6tB_uwFg"
   },
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yX_QgSKDLkVQ"
   },
   "outputs": [],
   "source": [
    "def calculate_cost(A2, Y):\n",
    "\n",
    "  ## Cross entropy loss for a single input\n",
    "  cost = -np.sum(np.multiply(Y, np.log(A2)))\n",
    "  cost = np.squeeze(cost)\n",
    "\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hA7rzYqC2Pkf"
   },
   "source": [
    "    Here we  created a function to calculate accuarcy.\n",
    "    It returns mismatches along with accuracy if the print_mismatch is set to be true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AS6R1-Wiuzk7"
   },
   "source": [
    "### Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpA4IUmBqhFh"
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted, print_mismatch=False):\n",
    "  \n",
    "  mismatch={}\n",
    "  correct = 0\n",
    "  for i in range(len(actual)):\n",
    "    if actual[i] == predicted[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        if print_mismatch == True:\n",
    "          actual_word= list_of_words[np.argmax(actual[i])]\n",
    "          predicted_word= list_of_words[np.argmax(predicted[i])]\n",
    "          mismatch[actual_word] = predicted_word\n",
    "          \n",
    "  accuracy= correct / float(len(actual)) * 100.0\n",
    "  if print_mismatch==True:\n",
    "    return(accuracy, mismatch)\n",
    "  else:\n",
    "    return(accuracy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-T2ZzRGx23Ou"
   },
   "source": [
    "    The model function takes input, output, parameters and learning rate as input.\n",
    "    It just assembles the functions.\n",
    "    1. Forward Propagation\n",
    "       Get the predicted output and the cost.\n",
    "    2. Backward Propagation\n",
    "       Get the gradients.\n",
    "    3. Update the parameters.\n",
    "\n",
    "    Returns the parameters and cost as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsFBSjt9iamd"
   },
   "outputs": [],
   "source": [
    "def model(X, Y, parameters,learning_rate):\n",
    "   \n",
    "    fp_output = forward_propagation(X, parameters)\n",
    "    A2= fp_output[\"A2\"]\n",
    "\n",
    "    cost = calculate_cost(A2, Y)\n",
    "\n",
    "    gradients = backward_propagation(X, Y, fp_output, parameters)\n",
    "\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "\n",
    "    return parameters,cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6wkDgpXu9yL"
   },
   "source": [
    "### Function for Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rh0HHd0p3p8K"
   },
   "source": [
    "    Here we write a function to predict the output for an unknown case.\n",
    "\n",
    "    It returns the probability corresponding to each output class if we set prob as true.\n",
    "\n",
    "    It returns the index where the we get the maxumum probabiliy if we set index as true.\n",
    "\n",
    "    It returns predicted word if we set word as true.\n",
    "\n",
    "    It returns the output vector if all the above is set to false as in the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eHX34F08T1v"
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters,index= False, word=False,prob=False):\n",
    "    fp_output = forward_propagation(X, parameters)\n",
    "    A2= fp_output[\"A2\"]\n",
    "    yhat = A2\n",
    "    yhat = np.squeeze(yhat)\n",
    "    \n",
    "    out=np.argmax(yhat)\n",
    "\n",
    "    output=[0 for i in range(len(yhat))]\n",
    "    output[out]=1\n",
    "\n",
    "    if index==True:\n",
    "      return out\n",
    "\n",
    "    if prob==True:\n",
    "        return(yhat)\n",
    "\n",
    "    if word==True:\n",
    "        return(list_of_words[out])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqM-eM1xwtEt"
   },
   "source": [
    "### Function for training\n",
    "(Using Stochastic Gradient Descent)\n",
    "\n",
    "    This function update parameters after calculating loss after feeding each input.\n",
    "\n",
    "    One epoch gets completed after all the input is fed to the network.\n",
    "\n",
    "    Then we do the above step for given no of iterations.\n",
    "\n",
    "    The function prints cost and accuracy after 100 epochs.\n",
    "\n",
    "    Here if we set the print_mismatch argument true, then it prints the cases where the predicted word doesn't match with the actual word.\n",
    "\n",
    "    The function finally returns the learned parameters which will be used during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeK0cnAMQAtm"
   },
   "outputs": [],
   "source": [
    "def train(encoded_words,label,hidden_layer_size,num_of_iters,learning_rate, print_mismatch= False):\n",
    "\n",
    "    input_size = len(encoded_words[0])\n",
    "    output_size= len(label[0])\n",
    "    parameters= initialize_parameters(input_size, hidden_layer_size, output_size)\n",
    "    actual = label\n",
    "  \n",
    "    ##  Loop for no of iterations\n",
    "    for k in tn(range(0, num_of_iters+1), unit= \" Epoch\"):\n",
    "        index=0\n",
    "        cost=0\n",
    "        \n",
    "        predicted =[]\n",
    "\n",
    "        for i in encoded_words:\n",
    "\n",
    "            X=np.array([i])\n",
    "            Y=np.array([label[index]])\n",
    "              \n",
    "            trained_parameters,cost = model(X, Y, parameters,learning_rate)\n",
    "            parameters= trained_parameters  \n",
    "\n",
    "            cost+=cost\n",
    "            index+=1\n",
    "\n",
    "        for i in encoded_words:\n",
    "          i=np.array([i])\n",
    "          predicted.append(predict(i, trained_parameters))\n",
    "\n",
    "        if print_mismatch== True:\n",
    "            if k==num_of_iters :\n",
    "              accuracy, mismatch = accuracy_metric(actual,predicted,print_mismatch=True)\n",
    "            else:\n",
    "              accuracy = accuracy_metric(actual,predicted,print_mismatch=False)\n",
    "\n",
    "        else:\n",
    "            accuracy = accuracy_metric(actual,predicted,print_mismatch=False)\n",
    "\n",
    "        ## Print the result after each 100 iterations\n",
    "        if(k%100 == 0):\n",
    "            print('Cost after iteration, {:d}: {:f}'.format(k, cost))\n",
    "            print('Accuracy after iteration, {:d}: {:f}'.format(k, accuracy))\n",
    "\n",
    "        if (k==num_of_iters) and print_mismatch== True:\n",
    "          print(\"\\n\")\n",
    "          print(\"Mismatches:\",mismatch)\n",
    "          \n",
    "    return trained_parameters      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MLgHqprw1I2"
   },
   "source": [
    "### Example with a simple case\n",
    "\n",
    "\n",
    "    One simple example is shown to show whether the model works or not.\n",
    "\n",
    "    This is nothing but the XOR gate.\n",
    "\n",
    "    When we give (0,0),(0,1),(1,0),(1,1) as input we expect the output as 0,1,1,0 respectively.\n",
    "\n",
    "    But here I have kept two nodes in the output. First node correspond to zero and second node correspond to 1 i.e. if we get [1,0] as ouput then in true sense the output is zero and 1 if we get [0,1] as output. We just need to take argmax for the desired result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCjWQUDZw63w"
   },
   "outputs": [],
   "source": [
    "inp=[[0,0],[0,1],[1,0],[1,1]]\n",
    "out=[[1,0],[0,1],[0,1],[1,0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457,
     "referenced_widgets": [
      "a9284af5094f4c7dbdc9ad63b7b049e7",
      "467781076f48425db7dd91327218b109",
      "33b4ed5604384c80a568e09848d42abf",
      "7d9baee82b0c45398146794fcef73e2f",
      "51eea71b38dd4214858d8fb0970d3c67",
      "40dfda284f064136bbdcd59c4385e772",
      "c3980814c93d4a999a8407b8d0e10dcd",
      "7256654f0d3946d8a639d4200b11a3f3"
     ]
    },
    "colab_type": "code",
    "id": "atWmRjT4w7H1",
    "outputId": "e19f2d0c-3303-4327-96bf-8976b655d535"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9284af5094f4c7dbdc9ad63b7b049e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1001), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration, 0: 8.295265\n",
      "Accuracy after iteration, 0: 25.000000\n",
      "Cost after iteration, 100: 0.082929\n",
      "Accuracy after iteration, 100: 100.000000\n",
      "Cost after iteration, 200: 0.036422\n",
      "Accuracy after iteration, 200: 100.000000\n",
      "Cost after iteration, 300: 0.022591\n",
      "Accuracy after iteration, 300: 100.000000\n",
      "Cost after iteration, 400: 0.016132\n",
      "Accuracy after iteration, 400: 100.000000\n",
      "Cost after iteration, 500: 0.012438\n",
      "Accuracy after iteration, 500: 100.000000\n",
      "Cost after iteration, 600: 0.010066\n",
      "Accuracy after iteration, 600: 100.000000\n",
      "Cost after iteration, 700: 0.008421\n",
      "Accuracy after iteration, 700: 100.000000\n",
      "Cost after iteration, 800: 0.007218\n",
      "Accuracy after iteration, 800: 100.000000\n",
      "Cost after iteration, 900: 0.006302\n",
      "Accuracy after iteration, 900: 100.000000\n",
      "Cost after iteration, 1000: 0.005583\n",
      "Accuracy after iteration, 1000: 100.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learned_parameters = train(inp, out, 4, 1000,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0ibZi5j465z"
   },
   "source": [
    "### Prediction for the test case of XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "wgMBGxthxx4y",
    "outputId": "2aef6811-2ee2-4eef-aba0-ff8ce75f2d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xor value for input [[0 0]] is: 0\n",
      "Xor value for input [[0 1]] is: 1\n",
      "Xor value for input [[1 0]] is: 1\n",
      "Xor value for input [[1 1]] is: 0\n"
     ]
    }
   ],
   "source": [
    "X_test=[[0,0],[0,1],[1,0],[1,1]]\n",
    "for i in X_test:\n",
    "  X = np.array([i])  \n",
    "  y_predict = predict(X, learned_parameters,prob=False)\n",
    "  # Print the result\n",
    "  print(\"Xor value for input {} is: {:d}\".format(X,np.argmax(y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eueDfJFxvNxe"
   },
   "source": [
    "    The model works. We don't have other test examples here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58Pnlm99qqJ0"
   },
   "source": [
    "### Training and testing for actual task\n",
    "For Five length input(26 dimensional vector) and 128 length output(one hot vector for words)\n",
    "\n",
    "    Here we do the main task.\n",
    "    Steps:\n",
    "\n",
    "    1. First We take 128 five length words.\n",
    "       We make all the letters in each word in lower case.\n",
    "    2. Then we create 26 dimensional vector for each word based on the letters.\n",
    "       Here we create a 26 dimensional zero vector. Then we put 1 in the position corresponding to a letter.\n",
    "    3. Then we create a input matrix (which will be fed as input in the main function) which keeps encoded vectors for each word\n",
    "    4. Then we create the 128 dimensional output vector.\n",
    "       It is one hot encoding of the 128 words.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzvEaTIi8T8n"
   },
   "source": [
    "## Create Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cQdN630r-kz"
   },
   "source": [
    "### List of Five letter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFo0rgXu8T8x"
   },
   "outputs": [],
   "source": [
    "list_of_words=[\"seven\",\"world\",\"about\",\"again\",\"heart\",\"pizza\",\"water\",\"happy\",\"sixty\",\"board\",\"month\",\"Angel\",\"death\",\"green\",\"music\",\"fifty\",\"three\",\"party\",\"piano\",\"Kelly\",\"mouth\",\"woman\",\"sugar\",\"amber\",\"dream\",\"apple\",\"laugh\",\"tiger\",\"faith\",\"earth\",\"river\",\"money\",\"peace\",\"forty\",\"words\",\"smile\",\"abate\",\"house\",\"alone\",\"watch\",\"lemon\",\"South\",\"erica\",\"anime\",\"after\",\"santa\",\"women\",\"admin\",\"Jesus\",\"stone\",\"blood\",\"megan\",\"thing\",\"light\",\"David\",\"cough\",\"story\",\"power\",\"India\",\"point\",\"today\",\"Sarah\",\"anger\",\"Night\",\"glory\",\"April\",\"candy\",\"puppy\",\"above\",\"phone\",\"chris\",\"vegan\",\"forum\",\"Jason\",\"Irish\",\"birth\",\"other\",\"grace\",\"queen\",\"pasta\",\"plant\",\"Jacob\",\"smart\",\"knife\",\"magic\",\"jelly\",\"black\",\"media\",\"honor\",\"cycle\",\"truth\",\"zebra\",\"train\",\"bully\",\"chain\",\"brain\",\"mango\",\"under\",\"dirty\",\"Eight\",\"fruit\",\"kevin\",\"panda\",\"truck\",\"field\",\"bible\",\"radio\",\"dance\",\"voice\",\"smith\",\"sorry\",\"Paris\",\"being\",\"lover\",\"never\",\"royal\",\"Venus\",\"metal\",\"Henry\",\"penny\",\"north\",\"bread\",\"daily\",\"paper\",\"beard\",\"alive\",\"place\",\"chair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n9pjjOVC8T9C",
    "outputId": "fdd148a7-0b77-4bfd-8585-9cb3bf4f143a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words: 128\n"
     ]
    }
   ],
   "source": [
    "print(\"No of words:\",len(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rVfOnkGv8T9Q"
   },
   "outputs": [],
   "source": [
    "alphabet= \"abcdefghijklmnopqrstuvwxyz\"\n",
    "dic_alphabet= {alphabet[i]:i for i in range(len(alphabet))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "K6-I-3ul8T9t",
    "outputId": "c0167979-663a-4550-be31-74547397283e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
     ]
    }
   ],
   "source": [
    "print(dic_alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oc5MP9BIypPY"
   },
   "source": [
    "### Encoding of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoJCKSuA8T-v"
   },
   "outputs": [],
   "source": [
    "def encoded_word(word):\n",
    "\n",
    "    output=[0 for i in range(26)]\n",
    "    \n",
    "    for i in word:\n",
    "        if i not in dic_alphabet.keys():\n",
    "            print(\"Wrong Input\")\n",
    "            print(i)\n",
    "        else:\n",
    "            output[dic_alphabet[i]]+=1\n",
    "    \n",
    "    output= [x / len(word) for x in output]      \n",
    "    \n",
    "    return output        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE23AkIG0HVK"
   },
   "source": [
    "### Convert words to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64htQFU28T-6"
   },
   "outputs": [],
   "source": [
    "for i in range(len(list_of_words)):\n",
    "        list_of_words[i]=list_of_words[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUdADwa_R6TN"
   },
   "outputs": [],
   "source": [
    "input_dic = {i:list_of_words[i] for i in range(len(list_of_words))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stI2WVay0NCX"
   },
   "source": [
    "### Input to pass in the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrhnNLD68T_L"
   },
   "outputs": [],
   "source": [
    "input_matrix= []\n",
    "for i in range(len(list_of_words)):\n",
    "    input_matrix.append(encoded_word(list_of_words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQoTj8Cm8UAN"
   },
   "source": [
    "### Create Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "en6znlB68UAT"
   },
   "outputs": [],
   "source": [
    "label=[[0 for i in range(128)] for j in range(128)]\n",
    "for i in range(len(list_of_words)):\n",
    "    label[i][i]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN5N4hAE0dGR"
   },
   "source": [
    "### Main model train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OePS7OMaxap8"
   },
   "source": [
    "    Here we train our model.\n",
    "    Input matrix and label which are created in the previous step are given as input. \n",
    "    We also give no of iterations as input and learning rate.\n",
    "    It also print the mismatches in the training if print_mismatch is set to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866,
     "referenced_widgets": [
      "9eaff32ea8fe4382bf3ce2d51d03ac5f",
      "6b59a92cb8374d9da2469c404a53486f",
      "5eab02017f6b4756a6358c4f5c46698e",
      "30ca11a5863c433ead4e47303df1e436",
      "b3efba248d634472a64b6969ca72208f",
      "9ddc87eb49df4d35be3c703a2d191423",
      "6c633106217546869a65fde4b8b97dbc",
      "03646788ad804bd2bf95ab5fe1facb18"
     ]
    },
    "colab_type": "code",
    "id": "4Nlpel3e0bu5",
    "outputId": "7d8ba1a7-a3bb-4619-dff5-a4e08525bcd5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaff32ea8fe4382bf3ce2d51d03ac5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration, 0: 13.816395\n",
      "Accuracy after iteration, 0: 0.781250\n",
      "Cost after iteration, 100: 0.746036\n",
      "Accuracy after iteration, 100: 97.656250\n",
      "Cost after iteration, 200: 0.231450\n",
      "Accuracy after iteration, 200: 97.656250\n",
      "Cost after iteration, 300: 0.129274\n",
      "Accuracy after iteration, 300: 97.656250\n",
      "Cost after iteration, 400: 0.087786\n",
      "Accuracy after iteration, 400: 97.656250\n",
      "Cost after iteration, 500: 0.065785\n",
      "Accuracy after iteration, 500: 97.656250\n",
      "Cost after iteration, 600: 0.052307\n",
      "Accuracy after iteration, 600: 97.656250\n",
      "Cost after iteration, 700: 0.043263\n",
      "Accuracy after iteration, 700: 97.656250\n",
      "Cost after iteration, 800: 0.036802\n",
      "Accuracy after iteration, 800: 97.656250\n",
      "Cost after iteration, 900: 0.031969\n",
      "Accuracy after iteration, 900: 97.656250\n",
      "Cost after iteration, 1000: 0.028226\n",
      "Accuracy after iteration, 1000: 97.656250\n",
      "Cost after iteration, 1100: 0.025247\n",
      "Accuracy after iteration, 1100: 97.656250\n",
      "Cost after iteration, 1200: 0.022823\n",
      "Accuracy after iteration, 1200: 97.656250\n",
      "Cost after iteration, 1300: 0.020814\n",
      "Accuracy after iteration, 1300: 97.656250\n",
      "Cost after iteration, 1400: 0.019124\n",
      "Accuracy after iteration, 1400: 97.656250\n",
      "Cost after iteration, 1500: 0.017683\n",
      "Accuracy after iteration, 1500: 97.656250\n",
      "Cost after iteration, 1600: 0.016441\n",
      "Accuracy after iteration, 1600: 97.656250\n",
      "Cost after iteration, 1700: 0.015360\n",
      "Accuracy after iteration, 1700: 97.656250\n",
      "Cost after iteration, 1800: 0.014412\n",
      "Accuracy after iteration, 1800: 97.656250\n",
      "Cost after iteration, 1900: 0.013573\n",
      "Accuracy after iteration, 1900: 97.656250\n",
      "Cost after iteration, 2000: 0.012826\n",
      "Accuracy after iteration, 2000: 97.656250\n",
      "\n",
      "\n",
      "Mismatches: {'heart': 'earth', 'thing': 'night', 'bread': 'beard'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_parameters= train(input_matrix, label, 10, 2000, 0.1, print_mismatch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9fodRZultBj"
   },
   "source": [
    "### Testing\n",
    "\n",
    "    Steps:\n",
    "    1. We take the test examples.\n",
    "    2. We take the actual words (that we want as output) corresponding to the examples taken.\n",
    "    3. Then we predict the words using the predict function based on the learned parameters.\n",
    "    4. Then we check where the correct and wrong prediction occured.\n",
    "    5. Then we calculate the test accuracy.\n",
    "       The test accuracy highly depends on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZZqNh5gQfGC"
   },
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Yv7NBEo0brm"
   },
   "outputs": [],
   "source": [
    "test_words= [\"hapqy\",\"todey\",\"chrid\",\"applo\",\"knofe\",\"porty\",\"matel\",\"chais\",\"redio\",\"naver\",\"cykle\",\"pland\",\"hodor\",\"dence\",\"poyer\",\"piaza\",\"momth\",\"grean\",\"rivar\",\"kight\",\"traen\"]\n",
    "actual_words = [\"happy\",\"today\",\"chris\",\"apple\",\"knife\",\"forty\",\"metal\",\"chain\",\"radio\",\"never\",\"cycle\",\"plant\",\"honor\",\"dance\",\"power\",\"pizza\",\"month\",\"green\",\"river\",\"night\",\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmhT8Yn9QlRO"
   },
   "source": [
    "### For Predicting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcKvzCXSl1ee"
   },
   "outputs": [],
   "source": [
    "predicted_words=[]\n",
    "for i in test_words:\n",
    "  encode_word=encoded_word(i)\n",
    "  X=np.array([encode_word])\n",
    "  predicted= predict(X, trained_parameters,index= True)\n",
    "  predicted_words.append(input_dic[predicted])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWkvCPSn0R7m"
   },
   "source": [
    "### Check for the Correct and wrong prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "sdgHjUnfmcD5",
    "outputId": "9f384e92-0f65-49a0-b20a-de40b83cbc9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test word: hapqy , Actual: happy , predicted: happy ---- Correct Prediction\n",
      "Test word: todey , Actual: today , predicted: lover ---- Wrong Prediction\n",
      "Test word: chrid , Actual: chris , predicted: chris ---- Correct Prediction\n",
      "Test word: applo , Actual: apple , predicted: apple ---- Correct Prediction\n",
      "Test word: knofe , Actual: knife , predicted: knife ---- Correct Prediction\n",
      "Test word: porty , Actual: forty , predicted: forty ---- Correct Prediction\n",
      "Test word: matel , Actual: metal , predicted: metal ---- Correct Prediction\n",
      "Test word: chais , Actual: chain , predicted: jesus ---- Wrong Prediction\n",
      "Test word: redio , Actual: radio , predicted: voice ---- Wrong Prediction\n",
      "Test word: naver , Actual: never , predicted: never ---- Correct Prediction\n",
      "Test word: cykle , Actual: cycle , predicted: kelly ---- Wrong Prediction\n",
      "Test word: pland , Actual: plant , predicted: alone ---- Wrong Prediction\n",
      "Test word: hodor , Actual: honor , predicted: honor ---- Correct Prediction\n",
      "Test word: dence , Actual: dance , predicted: dance ---- Correct Prediction\n",
      "Test word: poyer , Actual: power , predicted: power ---- Correct Prediction\n",
      "Test word: piaza , Actual: pizza , predicted: pizza ---- Correct Prediction\n",
      "Test word: momth , Actual: month , predicted: mouth ---- Wrong Prediction\n",
      "Test word: grean , Actual: green , predicted: anger ---- Wrong Prediction\n",
      "Test word: rivar , Actual: river , predicted: river ---- Correct Prediction\n",
      "Test word: kight , Actual: night , predicted: night ---- Correct Prediction\n",
      "Test word: traen , Actual: train , predicted: train ---- Correct Prediction\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(actual_words)):\n",
    "  if actual_words[i]== predicted_words[i]:\n",
    "    print(\"Test word: {:s} , Actual: {:s} , predicted: {:s} ---- Correct Prediction\".format(test_words[i],actual_words[i],predicted_words[i]))\n",
    "  else:\n",
    "    print(\"Test word: {:s} , Actual: {:s} , predicted: {:s} ---- Wrong Prediction\".format(test_words[i],actual_words[i],predicted_words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_cLvhEs0Yno"
   },
   "source": [
    "### Calculate the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZscA9n8onZgZ",
    "outputId": "a15e9ded-6399-44b0-f450-03b2e47a0e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "test_accuracy= accuracy_metric(actual_words, predicted_words)\n",
    "print(\"Test Accuracy:\",test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yctwp0lzj5En"
   },
   "source": [
    "    Test accuracy depends on the given test examples. For some simple cases the model fails. For some cases it is able to predict the output correctly.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03646788ad804bd2bf95ab5fe1facb18": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30ca11a5863c433ead4e47303df1e436": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03646788ad804bd2bf95ab5fe1facb18",
      "placeholder": "​",
      "style": "IPY_MODEL_6c633106217546869a65fde4b8b97dbc",
      "value": "100% 2001/2001 [00:26&lt;00:00, 74.77 Epoch/s]"
     }
    },
    "33b4ed5604384c80a568e09848d42abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40dfda284f064136bbdcd59c4385e772",
      "max": 1001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51eea71b38dd4214858d8fb0970d3c67",
      "value": 1001
     }
    },
    "40dfda284f064136bbdcd59c4385e772": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "467781076f48425db7dd91327218b109": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51eea71b38dd4214858d8fb0970d3c67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5eab02017f6b4756a6358c4f5c46698e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ddc87eb49df4d35be3c703a2d191423",
      "max": 2001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3efba248d634472a64b6969ca72208f",
      "value": 2001
     }
    },
    "6b59a92cb8374d9da2469c404a53486f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c633106217546869a65fde4b8b97dbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7256654f0d3946d8a639d4200b11a3f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d9baee82b0c45398146794fcef73e2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7256654f0d3946d8a639d4200b11a3f3",
      "placeholder": "​",
      "style": "IPY_MODEL_c3980814c93d4a999a8407b8d0e10dcd",
      "value": "100% 1001/1001 [00:00&lt;00:00, 2696.58 Epoch/s]"
     }
    },
    "9ddc87eb49df4d35be3c703a2d191423": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eaff32ea8fe4382bf3ce2d51d03ac5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5eab02017f6b4756a6358c4f5c46698e",
       "IPY_MODEL_30ca11a5863c433ead4e47303df1e436"
      ],
      "layout": "IPY_MODEL_6b59a92cb8374d9da2469c404a53486f"
     }
    },
    "a9284af5094f4c7dbdc9ad63b7b049e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33b4ed5604384c80a568e09848d42abf",
       "IPY_MODEL_7d9baee82b0c45398146794fcef73e2f"
      ],
      "layout": "IPY_MODEL_467781076f48425db7dd91327218b109"
     }
    },
    "b3efba248d634472a64b6969ca72208f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3980814c93d4a999a8407b8d0e10dcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
